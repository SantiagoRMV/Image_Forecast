{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamiento y detección de vacios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vacíos detectados:\n",
      "1. Desde 2023-07-01 21:20:21 hasta 2023-07-01 23:10:21 (10 imágenes faltantes)\n",
      "Error: invalid literal for int() with base 10: ''. Por favor, ingrese un número válido.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# Parámetros\n",
    "expected_interval = 10  # Intervalo esperado en minutos entre imágenes\n",
    "image_folder = \"../data/Images_test/\"\n",
    "\n",
    "# Listar y ordenar imágenes por timestamp\n",
    "images = []\n",
    "for file in os.listdir(image_folder):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        # Extraer el timestamp del nombre de la imagen\n",
    "        timestamp_str = file.split(\"_\")[3][1:][:-4]  # Ajustar según el formato de los nombres\n",
    "        timestamp = datetime.strptime(timestamp_str, \"%Y%m%d%H%M%S\")\n",
    "        images.append((file, timestamp))\n",
    "\n",
    "# Ordenar las imágenes por timestamp\n",
    "images = sorted(images, key=lambda x: x[1])\n",
    "\n",
    "# Detectar vacíos en la secuencia\n",
    "gaps = []\n",
    "for i in range(len(images) - 1):\n",
    "    current_time = images[i][1]\n",
    "    next_time = images[i + 1][1]\n",
    "    delta = (next_time - current_time).total_seconds() / 60  # Diferencia en minutos\n",
    "    if delta > expected_interval:\n",
    "        gaps.append((current_time, next_time))\n",
    "\n",
    "# Mostrar los vacíos detectados\n",
    "print(\"Vacíos detectados:\")\n",
    "gap_info = []\n",
    "for idx, (start, end) in enumerate(gaps, start=1):\n",
    "    # Calcular el número de imágenes faltantes\n",
    "    missing_count = int((end - start).total_seconds() / 60 / expected_interval) - 1\n",
    "    gap_info.append((start, end, missing_count))\n",
    "    print(f\"{idx}. Desde {start} hasta {end} ({missing_count} imágenes faltantes)\")\n",
    "\n",
    "# Preguntar al usuario qué vacío desea llenar\n",
    "if gap_info:\n",
    "    try:\n",
    "        selected_index = int(input(\"\\nSeleccione el índice del vacío que desea llenar: \"))\n",
    "        if selected_index < 1 or selected_index > len(gap_info):\n",
    "            raise ValueError(\"Índice fuera de rango.\")\n",
    "        selected_gap = gap_info[selected_index - 1]\n",
    "        start_gap, end_gap, missing_count = selected_gap\n",
    "        print(f\"\\nHas seleccionado llenar el rango desde {start_gap} hasta {end_gap}, con {missing_count} imágenes faltantes.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: {e}. Por favor, ingrese un número válido.\")\n",
    "else:\n",
    "    print(\"No se detectaron vacíos en la secuencia.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imágenes seleccionadas como entrada (10):\n",
      "OR_ABI-L2-ACMF-M6_G16_s20230701194021.jpg\n",
      "OR_ABI-L2-ACMF-M6_G16_s20230701195021.jpg\n",
      "OR_ABI-L2-ACMF-M6_G16_s20230701200021.jpg\n",
      "OR_ABI-L2-ACMF-M6_G16_s20230701201021.jpg\n",
      "OR_ABI-L2-ACMF-M6_G16_s20230701202021.jpg\n",
      "OR_ABI-L2-ACMF-M6_G16_s20230701203021.jpg\n",
      "OR_ABI-L2-ACMF-M6_G16_s20230701204021.jpg\n",
      "OR_ABI-L2-ACMF-M6_G16_s20230701205021.jpg\n",
      "OR_ABI-L2-ACMF-M6_G16_s20230701210021.jpg\n",
      "OR_ABI-L2-ACMF-M6_G16_s20230701211021.jpg\n"
     ]
    }
   ],
   "source": [
    "# Listar y ordenar imágenes por timestamp\n",
    "image_list = []\n",
    "for file in os.listdir(image_folder):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        # Extraer el timestamp del nombre de la imagen\n",
    "        timestamp_str = file.split(\"_\")[3][1:][:-4]  # Ajustar según el formato de los nombres\n",
    "        timestamp = datetime.strptime(timestamp_str, \"%Y%m%d%H%M%S\")\n",
    "        image_list.append((file, timestamp))\n",
    "\n",
    "# Ordenar por timestamp\n",
    "image_list = sorted(image_list, key=lambda x: x[1])\n",
    "\n",
    "# Función para obtener las imágenes disponibles antes del vacío\n",
    "def get_images_before_gap(images, gap_start, num_images=10):\n",
    "    \"\"\"\n",
    "    Recupera las imágenes previas al inicio de un vacío.\n",
    "    \n",
    "    Args:\n",
    "        images (list): Lista de imágenes ordenadas por timestamp.\n",
    "        gap_start (datetime): Timestamp del inicio del vacío.\n",
    "        num_images (int): Número de imágenes a recuperar.\n",
    "\n",
    "    Returns:\n",
    "        list: Imágenes seleccionadas previas al vacío.\n",
    "    \"\"\"\n",
    "    # Filtrar imágenes con timestamps anteriores al inicio del vacío\n",
    "    images_before_gap = [img for img in images if img[1] < gap_start]\n",
    "    \n",
    "    # Seleccionar las últimas num_images imágenes\n",
    "    if len(images_before_gap) < num_images:\n",
    "        raise ValueError(f\"No hay suficientes imágenes antes del vacío para seleccionar {num_images}.\")\n",
    "    return images_before_gap[-num_images:]\n",
    "\n",
    "# Recuperar las imágenes previas al vacío seleccionado\n",
    "num_images_input = 10  # Ajusta según el modelo (ej. 5, 10, 20)\n",
    "input_images = get_images_before_gap(image_list, start_gap, num_images=num_images_input)\n",
    "\n",
    "# Mostrar las imágenes seleccionadas\n",
    "print(f\"Imágenes seleccionadas como entrada ({len(input_images)}):\")\n",
    "for img in input_images:\n",
    "    print(img[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre procesar imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imágenes preprocesadas: (10, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Parámetros del preprocesamiento\n",
    "target_size = (64, 64)  # Redimensionar las imágenes a 64x64\n",
    "\n",
    "# Función para preprocesar una imagen\n",
    "def preprocess_image(image_path, target_size):\n",
    "    \"\"\"Carga y preprocesa una imagen.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Ruta a la imagen.\n",
    "        target_size (tuple): Tamaño de salida (ancho, alto).\n",
    "    \n",
    "    Returns:\n",
    "        np.array: Imagen preprocesada.\n",
    "    \"\"\"\n",
    "    # Cargar la imagen en formato RGB\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Redimensionar\n",
    "    image = cv2.resize(image, target_size)\n",
    "    \n",
    "    # Normalizar valores de píxeles (0-255 -> 0-1)\n",
    "    image = image / 255.0\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Cargar y preprocesar las imágenes seleccionadas\n",
    "preprocessed_images = []\n",
    "for img_name, _ in input_images:\n",
    "    img_path = os.path.join(image_folder, img_name)\n",
    "    preprocessed_images.append(preprocess_image(img_path, target_size))\n",
    "\n",
    "# Convertir a un array numpy\n",
    "preprocessed_images = np.array(preprocessed_images)\n",
    "\n",
    "print(f\"Imágenes preprocesadas: {preprocessed_images.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamps faltantes: [datetime.datetime(2023, 7, 1, 21, 30, 21), datetime.datetime(2023, 7, 1, 21, 40, 21), datetime.datetime(2023, 7, 1, 21, 50, 21), datetime.datetime(2023, 7, 1, 22, 0, 21), datetime.datetime(2023, 7, 1, 22, 10, 21), datetime.datetime(2023, 7, 1, 22, 20, 21), datetime.datetime(2023, 7, 1, 22, 30, 21), datetime.datetime(2023, 7, 1, 22, 40, 21), datetime.datetime(2023, 7, 1, 22, 50, 21), datetime.datetime(2023, 7, 1, 23, 0, 21)]\n",
      "Imágenes faltantes preparadas: (10, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "# Generar los timestamps faltantes\n",
    "missing_timestamps = [\n",
    "    start_gap + timedelta(minutes=expected_interval * i)\n",
    "    for i in range(1, missing_count + 1)\n",
    "]\n",
    "\n",
    "# Verificar los timestamps generados\n",
    "print(f\"Timestamps faltantes: {missing_timestamps}\")\n",
    "\n",
    "# Crear un placeholder para las imágenes faltantes\n",
    "missing_images = []\n",
    "for ts in missing_timestamps:\n",
    "    # Placeholder con el tamaño 64x64 y 3 canales\n",
    "    missing_images.append(np.zeros((64, 64, 3), dtype=np.float32))\n",
    "\n",
    "# Convertir a un array numpy\n",
    "missing_images = np.array(missing_images)\n",
    "\n",
    "print(f\"Imágenes faltantes preparadas: {missing_images.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 20, 64, 64, 3)]   0         \n",
      "                                                                 \n",
      " time_distributed_6 (TimeDi  (None, 20, 2, 2, 512)     14714688  \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_7 (TimeDi  (None, 20, 2, 2, 512)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " conv_lstm2d_2 (ConvLSTM2D)  (None, 20, 2, 2, 64)      1327360   \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 20, 2, 2, 64)      256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv_lstm2d_3 (ConvLSTM2D)  (None, 20, 2, 2, 64)      295168    \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 20, 2, 2, 64)      256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " time_distributed_8 (TimeDi  (None, 20, 256)           0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_9 (TimeDi  (None, 20, 12288)         3158016   \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_10 (TimeD  (None, 20, 64, 64, 3)     0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_11 (TimeD  (None, 20, 593, 449, 3)   0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19495744 (74.37 MB)\n",
      "Trainable params: 19495488 (74.37 MB)\n",
      "Non-trainable params: 256 (1.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, TimeDistributed, ConvLSTM2D, BatchNormalization, Dense, Reshape, Lambda, Flatten\n",
    ")\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "# Función para redimensionar imágenes dentro del modelo\n",
    "def resize_output_to_original(x):\n",
    "    return tf.image.resize(x, [593, 449], method=\"bilinear\")\n",
    "\n",
    "# Modelo base VGG16 para extracción de características\n",
    "def build_vgg16_extractor(input_shape=(64, 64, 3)):\n",
    "    vgg = VGG16(include_top=False, weights=\"imagenet\", input_shape=input_shape)\n",
    "    model = Model(inputs=vgg.input, outputs=vgg.output)  # Mantén la salida convolucional\n",
    "    return model\n",
    "\n",
    "# Crear modelo VGG16 para extracción de características\n",
    "vgg16_extractor = build_vgg16_extractor()\n",
    "\n",
    "# Parámetros del modelo\n",
    "input_shape = (20, 64, 64, 3)  # Secuencia de 20 imágenes de 64x64x3\n",
    "latent_dim = 512  # Capacidad del LSTM\n",
    "\n",
    "# Entrada del modelo\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Extracción de características con VGG16\n",
    "x = TimeDistributed(vgg16_extractor)(input_layer)  # Procesa cada imagen de la secuencia\n",
    "\n",
    "# Agregar dimensiones para usar con ConvLSTM\n",
    "x = TimeDistributed(Reshape((2, 2, 512)))(x)  # Cambia a 2x2x512 (forma típica de salida de VGG16)\n",
    "\n",
    "# ConvLSTM para capturar relaciones temporales\n",
    "x = ConvLSTM2D(filters=64, kernel_size=(3, 3), padding=\"same\", return_sequences=True)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ConvLSTM2D(filters=64, kernel_size=(3, 3), padding=\"same\", return_sequences=True)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "# Decodificación de salida\n",
    "x = TimeDistributed(Flatten())(x)  # Aplana la salida de ConvLSTM\n",
    "x = TimeDistributed(Dense(64 * 64 * 3, activation=\"relu\"))(x)  # Reconstruir dimensiones\n",
    "x = TimeDistributed(Reshape((64, 64, 3)))(x)  # Reconstruir forma original de la imagen\n",
    "\n",
    "# Redimensionar a tamaño original\n",
    "x = TimeDistributed(Lambda(resize_output_to_original))(x)\n",
    "\n",
    "# Crear modelo completo\n",
    "model = Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss=\"mse\")\n",
    "\n",
    "# Revisar arquitectura del modelo\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevo X_train shape: (64, 20, 64, 64, 3)\n",
      "Nuevo y_train shape: (64, 20, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "\n",
    "# Crear X_train y y_train\n",
    "sequence_length = 100  # Aumentamos el tamaño de las secuencias\n",
    "image_folder = \"../data/Images_test/\"\n",
    "images = []\n",
    "\n",
    "# Listar y ordenar imágenes por timestamp\n",
    "for file in os.listdir(image_folder):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        timestamp_str = file.split(\"_\")[3][1:][:-4]  # Extraer timestamp del nombre\n",
    "        timestamp = datetime.strptime(timestamp_str, \"%Y%m%d%H%M%S\")\n",
    "        images.append((file, timestamp))\n",
    "\n",
    "images = sorted(images, key=lambda x: x[1])  # Ordenar por timestamp\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(len(images) - 2 * sequence_length):\n",
    "    current_seq = images[i:i + sequence_length]\n",
    "    next_seq = images[i + sequence_length:i + 2 * sequence_length]\n",
    "    # Verificar si las secuencias son consecutivas\n",
    "    if (next_seq[0][1] - current_seq[-1][1]).total_seconds() / 60 == 10:  # 10 minutos de diferencia\n",
    "        # Procesar imágenes para entrada y salida\n",
    "        X = [preprocess_image(os.path.join(image_folder, img[0]), target_size=(64, 64)) for img in current_seq]\n",
    "        y = [preprocess_image(os.path.join(image_folder, img[0]), target_size=(64, 64)) for img in next_seq]\n",
    "        X_train.append(X)\n",
    "        y_train.append(y)\n",
    "\n",
    "# Convertir a arrays numpy\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print(f\"Nuevo X_train shape: {X_train.shape}\")\n",
    "print(f\"Nuevo y_train shape: {y_train.shape}\")\n",
    "\n",
    "# Redimensionar las salidas al tamaño original\n",
    "def resize_y_data(y_data, target_size=(593, 449)):\n",
    "    resized_data = []\n",
    "    for seq in y_data:\n",
    "        resized_seq = [cv2.resize(img, (target_size[1], target_size[0])) for img in seq]\n",
    "        resized_data.append(resized_seq)\n",
    "    return np.array(resized_data)\n",
    "\n",
    "y_train_resized = resize_y_data(y_train)\n",
    "\n",
    "# Dividir los datos en entrenamiento y validación\n",
    "X_train, X_val, y_train_resized, y_val_resized = train_test_split(\n",
    "    X_train, y_train_resized, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Normalizar los datos\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "y_train_resized = y_train_resized / 255.0\n",
    "y_val_resized = y_val_resized / 255.0\n",
    "\n",
    "# Verificar las formas de los datos\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train_resized shape: {y_train_resized.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"y_val_resized shape: {y_val_resized.shape}\")\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint(\"best_model_vgg16_lstm.h5\", save_best_only=True, monitor=\"val_loss\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train_resized,\n",
    "    validation_data=(X_val, y_val_resized),\n",
    "    epochs=20,  # Ajustar según los recursos y el tamaño del dataset\n",
    "    batch_size=4,  # Reducir si hay problemas de memoria\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Guardar el modelo final\n",
    "model.save(\"final_model_vgg16_lstm.h5\")\n",
    "\n",
    "# Verificar que el modelo se ha entrenado y guardado correctamente\n",
    "print(\"Entrenamiento finalizado. Modelo guardado como 'final_model_vgg16_lstm.h5'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validacion del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo entrenado\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_path = \"final_model_vgg16_lstm.h5\"  # Cambia por la ruta correcta si es necesario\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Preprocesar las imágenes seleccionadas para el vacío\n",
    "X_input = np.expand_dims(preprocessed_images, axis=0)  # Agregar dimensión batch\n",
    "\n",
    "# Generar las imágenes faltantes\n",
    "y_pred = model.predict(X_input)\n",
    "\n",
    "print(f\"Imágenes generadas: {y_pred.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "output_folder = \"../data/Images_Forecast\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Guardar las imágenes generadas\n",
    "for pred_image, timestamp in zip(y_pred[0], missing_timestamps):\n",
    "    # Desnormalizar la imagen\n",
    "    pred_image = (pred_image * 255).astype(np.uint8)\n",
    "\n",
    "    # Redimensionar al tamaño original (593x449)\n",
    "    pred_image_resized = cv2.resize(pred_image, (449, 593))\n",
    "\n",
    "    # Crear el nombre del archivo\n",
    "    output_name = f\"OR_ABI-L2-ACMF-M6_G16_s{timestamp.strftime('%Y%m%d%H%M%S')}.jpg\"\n",
    "    output_path = os.path.join(output_folder, output_name)\n",
    "\n",
    "    # Guardar la imagen\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(pred_image_resized, cv2.COLOR_RGB2BGR))\n",
    "    print(f\"Imagen generada guardada en: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
