{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secuencias cargadas: (103, 8, 480, 480, 3)\n",
      "Imágenes futuras: (103, 4, 480, 480, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Parámetros\n",
    "future_steps = 4  # Número de imágenes futuras a predecir\n",
    "sequence_length = 8  # Número de imágenes en la secuencia de entrada\n",
    "height, width, channels = 480, 480, 3  # Tamaño de las imágenes\n",
    "image_folder = '../data/Images_test/'  # Cambia esto a la ruta de tu carpeta\n",
    "forecast_folder = '../data/Images_Forecast'  # Carpeta donde se guardarán predicciones\n",
    "\n",
    "# Crear la carpeta de predicción si no existe\n",
    "os.makedirs(forecast_folder, exist_ok=True)\n",
    "\n",
    "def get_timestamp_from_filename(filename):\n",
    "    \"\"\"Extrae el timestamp del nombre del archivo.\"\"\"\n",
    "    base = os.path.basename(filename)\n",
    "    try:\n",
    "        timestamp_str = base.split('_')[3][1:].split('.')[0]  # Elimina el sufijo '.jpg'\n",
    "        return datetime.strptime(timestamp_str, '%Y%m%d%H%M%S')\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"No se pudo extraer el timestamp de: {filename}. Error: {e}\")\n",
    "\n",
    "def load_and_preprocess_image(image_path, target_size=(height, width)):\n",
    "    \"\"\"Carga y preprocesa una imagen.\"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"No se puede leer la imagen: {image_path}\")\n",
    "    image = cv2.resize(image, target_size)\n",
    "    image = image.astype('float32') / 255.0  # Normalización RGB\n",
    "    return image\n",
    "\n",
    "def load_image_sequences(folder, sequence_length, future_steps):\n",
    "    \"\"\"Carga secuencias de imágenes para entrenamiento/predicción.\"\"\"\n",
    "    image_files = sorted(\n",
    "        [os.path.join(folder, i) for i in os.listdir(folder) if i.endswith('.jpg')],\n",
    "        key=get_timestamp_from_filename,\n",
    "    )\n",
    "    X, y = [], []\n",
    "    timestamps = [get_timestamp_from_filename(f) for f in image_files]\n",
    "\n",
    "    # Verificar intervalos de tiempo de 10 minutos\n",
    "    valid_indices = []\n",
    "    for i in range(len(timestamps) - sequence_length - future_steps + 1):\n",
    "        is_valid = all(\n",
    "            (timestamps[i + j + 1] - timestamps[i + j]).total_seconds() == 600\n",
    "            for j in range(sequence_length + future_steps - 1)\n",
    "        )\n",
    "        if is_valid:\n",
    "            valid_indices.append(i)\n",
    "\n",
    "    # Cargar las secuencias\n",
    "    for idx in valid_indices:\n",
    "        sequence_images = [\n",
    "            load_and_preprocess_image(image_files[idx + j]) for j in range(sequence_length)\n",
    "        ]\n",
    "        future_images = [\n",
    "            load_and_preprocess_image(image_files[idx + sequence_length + k])\n",
    "            for k in range(future_steps)\n",
    "        ]\n",
    "        X.append(sequence_images)\n",
    "        y.append(future_images)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Cargar secuencias de imágenes\n",
    "try:\n",
    "    X, y = load_image_sequences(image_folder, sequence_length, future_steps)\n",
    "\n",
    "    # Mostrar información de las secuencias cargadas\n",
    "    print(f\"Secuencias cargadas: {X.shape}\")\n",
    "    print(f\"Imágenes futuras: {y.shape}\")\n",
    "\n",
    "    # Guardar las secuencias generadas como ejemplo\n",
    "    np.save(os.path.join(forecast_folder, \"X_sequences.npy\"), X)\n",
    "    np.save(os.path.join(forecast_folder, \"y_sequences.npy\"), y)\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rango disponible de imágenes:\n",
      "Inicia: 2023-07-01 05:00:21\n",
      "Termina: 2023-07-10 18:20:20\n",
      "\n",
      "Timestamps faltantes agrupados en rangos:\n",
      "1: Desde: 2023-07-06 05:00:21 Hasta: 2023-07-06 16:50:21\n",
      "2: Desde: 2023-07-07 05:00:21 Hasta: 2023-07-07 16:50:21\n",
      "3: Desde: 2023-07-07 18:30:21 Hasta: 2023-07-10 18:10:21\n",
      "\n",
      "Rango seleccionado: Desde 2023-07-06 05:00:21 Hasta 2023-07-06 16:50:21\n",
      "\n",
      "Se predecirán 72 imágenes en el rango seleccionado.\n",
      "Usando 10 imágenes para el entrenamiento.\n",
      "No se generaron suficientes secuencias de datos para entrenar el modelo.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Reshape, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# Configuración de rutas\n",
    "input_folder = '../data/Images/'  # Carpeta con las imágenes originales\n",
    "output_folder = '../data/Images_Forecast/'  # Carpeta para las imágenes predichas\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Dimensiones de las imágenes\n",
    "height, width, channels = 449, 593, 3\n",
    "sequence_length = 10  # Número de imágenes (1 día de datos)\n",
    "\n",
    "# Cargar el extractor de características VGG16\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(height, width, channels))\n",
    "flatten_layer = Flatten()(base_model.output)\n",
    "feature_extractor = Model(inputs=base_model.input, outputs=flatten_layer)\n",
    "\n",
    "# Función para cargar y normalizar una imagen\n",
    "def load_image(file_path):\n",
    "    img = cv2.imread(file_path)\n",
    "    img = cv2.resize(img, (width, height))  # Ajustar tamaño al esperado\n",
    "    img = preprocess_input(img)  # Preprocesar para VGG16\n",
    "    return img\n",
    "\n",
    "# Función para extraer características de secuencias de imágenes\n",
    "def extract_features(image_sequences):\n",
    "    num_sequences = len(image_sequences)\n",
    "    features = np.zeros((num_sequences, sequence_length, feature_extractor.output_shape[1]))\n",
    "\n",
    "    for i in range(num_sequences):\n",
    "        for j in range(sequence_length):\n",
    "            img = image_sequences[i, j]\n",
    "            img = np.expand_dims(img, axis=0)  # Expandir dimensión del lote\n",
    "            features[i, j] = feature_extractor.predict(img).squeeze()\n",
    "    return features\n",
    "\n",
    "# Preparar datos para entrenamiento\n",
    "def prepare_data(image_paths, sequence_length, future_steps):\n",
    "    images = [load_image(path) for path in image_paths]\n",
    "    X, y = [], []\n",
    "    for i in range(len(images) - sequence_length - future_steps + 1):\n",
    "        X.append(images[i:i + sequence_length])  # Secuencia de entrada\n",
    "        y.append(images[i + sequence_length:i + sequence_length + future_steps])  # Secuencia de salida\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Modelo LSTM dinámico\n",
    "def build_lstm_model(sequence_length, future_steps):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, input_shape=(sequence_length, feature_extractor.output_shape[1]), return_sequences=True))\n",
    "    model.add(LSTM(256, return_sequences=False))\n",
    "    model.add(Dense(future_steps * height * width * channels, activation='linear'))\n",
    "    model.add(Reshape((future_steps, height, width, channels)))  # Salida con múltiples imágenes\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# Leer y ordenar los nombres de imágenes por timestamp\n",
    "image_files = [f for f in os.listdir(input_folder) if f.endswith('.jpg')]\n",
    "timestamps = {datetime.strptime(f.split('_s')[1].split('.jpg')[0], '%Y%m%d%H%M%S'): f for f in image_files}\n",
    "timestamps_sorted = sorted(timestamps.keys())\n",
    "\n",
    "# Mostrar rango de fechas disponibles\n",
    "print(\"Rango disponible de imágenes:\")\n",
    "print(f\"Inicia: {timestamps_sorted[0]}\")\n",
    "print(f\"Termina: {timestamps_sorted[-1]}\")\n",
    "\n",
    "# Generar timestamps esperados en intervalos de 10 minutos\n",
    "expected_timestamps = []\n",
    "current_time = timestamps_sorted[0]\n",
    "while current_time <= timestamps_sorted[-1]:\n",
    "    expected_timestamps.append(current_time)\n",
    "    current_time += timedelta(minutes=10)\n",
    "\n",
    "# Identificar timestamps faltantes\n",
    "missing_timestamps = [ts for ts in expected_timestamps if ts not in timestamps]\n",
    "\n",
    "# Agrupar timestamps faltantes en rangos consecutivos\n",
    "def group_missing_timestamps(missing_timestamps):\n",
    "    if not missing_timestamps:\n",
    "        return []\n",
    "\n",
    "    ranges = []\n",
    "    start = missing_timestamps[0]\n",
    "    prev = missing_timestamps[0]\n",
    "\n",
    "    for ts in missing_timestamps[1:]:\n",
    "        if ts - prev > timedelta(minutes=10):\n",
    "            ranges.append((start, prev))\n",
    "            start = ts\n",
    "        prev = ts\n",
    "    ranges.append((start, prev))\n",
    "\n",
    "    return ranges\n",
    "\n",
    "missing_ranges = group_missing_timestamps(missing_timestamps)\n",
    "\n",
    "# Mostrar al usuario los rangos faltantes\n",
    "if missing_ranges:\n",
    "    print(\"\\nTimestamps faltantes agrupados en rangos:\")\n",
    "    for i, (start, end) in enumerate(missing_ranges, start=1):\n",
    "        print(f\"{i}: Desde: {start} Hasta: {end}\")\n",
    "\n",
    "    # Permitir que el usuario seleccione un rango por índice\n",
    "    try:\n",
    "        selected_index = int(input(\"\\nSeleccione el índice del rango a completar (por número): \"))\n",
    "        if selected_index < 1 or selected_index > len(missing_ranges):\n",
    "            raise ValueError(\"Índice fuera de rango.\")\n",
    "\n",
    "        # Obtener el rango seleccionado\n",
    "        start_date, end_date = missing_ranges[selected_index - 1]\n",
    "        print(f\"\\nRango seleccionado: Desde {start_date} Hasta {end_date}\")\n",
    "\n",
    "        # Filtrar los timestamps que caen dentro del rango seleccionado\n",
    "        timestamps_to_predict = [ts for ts in missing_timestamps if start_date <= ts <= end_date]\n",
    "        future_steps = len(timestamps_to_predict)  # Ajustar dinámicamente los futuros pasos\n",
    "        print(f\"\\nSe predecirán {future_steps} imágenes en el rango seleccionado.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: {e}. Por favor, ingrese un número válido.\")\n",
    "else:\n",
    "    print(\"No hay vacíos que completar en este momento.\")\n",
    "    timestamps_to_predict = []\n",
    "\n",
    "# Entrenar y predecir dinámicamente para llenar el vacío\n",
    "def train_and_predict_dynamic(images, timestamps_to_predict, feature_extractor, future_steps):\n",
    "    # Determinar cuántas imágenes están disponibles\n",
    "    available_images = len(images)\n",
    "    if available_images < sequence_length:\n",
    "        print(f\"No hay suficientes imágenes para entrenar. Imágenes disponibles: {available_images}\")\n",
    "        return\n",
    "\n",
    "    # Ajustar el número de imágenes de entrada al mínimo disponible\n",
    "    adjusted_sequence_length = min(sequence_length, available_images)\n",
    "    adjusted_images = images[-adjusted_sequence_length:]  # Últimas imágenes disponibles\n",
    "    print(f\"Usando {len(adjusted_images)} imágenes para el entrenamiento.\")\n",
    "\n",
    "    # Preparar datos para entrenamiento\n",
    "    image_paths = [os.path.join(input_folder, timestamps[ts]) for ts in timestamps_sorted if ts in timestamps]\n",
    "    X, y = prepare_data(image_paths[-adjusted_sequence_length:], adjusted_sequence_length, future_steps)\n",
    "\n",
    "    if len(X) == 0 or len(y) == 0:\n",
    "        print(f\"No se generaron suficientes secuencias de datos para entrenar el modelo.\")\n",
    "        return\n",
    "\n",
    "    X_features = extract_features(X)\n",
    "\n",
    "    # Construir el modelo\n",
    "    model = build_lstm_model(adjusted_sequence_length, future_steps)\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    reduce_lr = ReduceLROnPlateau(monitor=\"loss\", factor=0.5, patience=5, min_lr=1e-6)\n",
    "    model.fit(X_features, y, epochs=20, batch_size=16, callbacks=[reduce_lr])\n",
    "\n",
    "    # Realizar predicciones\n",
    "    predict_image_sequence(model, images, timestamps_to_predict, feature_extractor, future_steps)\n",
    "\n",
    "# Función para predecir una secuencia de imágenes\n",
    "def predict_image_sequence(model, images, timestamps_to_predict, feature_extractor, future_steps):\n",
    "    for i in range(0, len(timestamps_to_predict), future_steps):\n",
    "        # Usar las últimas imágenes disponibles\n",
    "        recent_images = images[-sequence_length:] if len(images) >= sequence_length else images\n",
    "        recent_images = np.array(recent_images)\n",
    "\n",
    "        # Extraer características de las últimas imágenes\n",
    "        recent_features = extract_features(recent_images[np.newaxis, :, :, :, :], feature_extractor)\n",
    "\n",
    "        # Predecir la secuencia de imágenes\n",
    "        predicted_sequence = model.predict(recent_features)[0]  # Secuencia de imágenes predichas\n",
    "\n",
    "        for step, predicted_image in enumerate(predicted_sequence):\n",
    "            if i + step >= len(timestamps_to_predict):  # Evitar índices fuera de rango\n",
    "                break\n",
    "            timestamp = timestamps_to_predict[i + step]\n",
    "            predicted_image = np.clip(predicted_image * 255, 0, 255).astype(np.uint8)  # Desnormalizar\n",
    "\n",
    "            # Guardar cada imagen predicha\n",
    "            predicted_file_name = f\"OR_ABI-L2-ACMF-M6_G16_s{timestamp.strftime('%Y%m%d%H%M%S')}.jpg\"\n",
    "            cv2.imwrite(os.path.join(output_folder, predicted_file_name), predicted_image)\n",
    "\n",
    "            # Añadir la imagen predicha a la lista de imágenes\n",
    "            images.append(predicted_image)\n",
    "\n",
    "    print(f\"\\nSe predijeron {len(timestamps_to_predict)} imágenes en el rango seleccionado.\")\n",
    "    print(f\"Imágenes guardadas en: {output_folder}\")\n",
    "\n",
    "# Realizar predicciones si hay vacíos seleccionados\n",
    "if timestamps_to_predict:\n",
    "    train_and_predict_dynamic(image_files, timestamps_to_predict, feature_extractor, future_steps)\n",
    "else:\n",
    "    print(\"No hay vacíos que completar en este momento.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
